{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "baf0e117",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:03:28.197728Z",
     "iopub.status.busy": "2024-06-04T07:03:28.197204Z",
     "iopub.status.idle": "2024-06-04T07:03:46.130094Z",
     "shell.execute_reply": "2024-06-04T07:03:46.128499Z"
    },
    "papermill": {
     "duration": 17.945159,
     "end_time": "2024-06-04T07:03:46.133115",
     "exception": false,
     "start_time": "2024-06-04T07:03:28.187956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.2.28-py3-none-any.whl.metadata (41 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.9.0.80)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.31.0)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.2+cpu)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.16.2+cpu)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.1)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\r\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.2.2)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\r\n",
      "Collecting ultralytics-thop>=0.2.5 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-0.2.7-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\r\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Downloading ultralytics-8.2.28-py3-none-any.whl (779 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-0.2.7-py3-none-any.whl (25 kB)\r\n",
      "Installing collected packages: ultralytics-thop, ultralytics\r\n",
      "Successfully installed ultralytics-8.2.28 ultralytics-thop-0.2.7\r\n"
     ]
    }
   ],
   "source": [
    "# !conda env create -f /kaggle/input/condaenv/environment.yml\n",
    "# !conda init\n",
    "# !conda activate pestvision\n",
    "# !wget -P /kaggle/input/ https://storage.googleapis.com/npss-pestvision-data/pestvision_data.zip\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e46b7279",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:03:46.152628Z",
     "iopub.status.busy": "2024-06-04T07:03:46.152073Z",
     "iopub.status.idle": "2024-06-04T07:03:54.925231Z",
     "shell.execute_reply": "2024-06-04T07:03:54.924226Z"
    },
    "papermill": {
     "duration": 8.786554,
     "end_time": "2024-06-04T07:03:54.928224",
     "exception": false,
     "start_time": "2024-06-04T07:03:46.141670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m This integration is tested and supported for ultralytics v8.0.238 and below.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m             Please report any issues to https://github.com/wandb/wandb/issues with the tag `yolov8`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "import imageio.v3 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import json\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from ultralytics import YOLO\n",
    "import wandb\n",
    "from wandb.integration.ultralytics import add_wandb_callback\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from glob import glob\n",
    "# from natsort import natsorted\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import List, Tuple, Optional, Callable, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "59da9b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:03:54.947540Z",
     "iopub.status.busy": "2024-06-04T07:03:54.946993Z",
     "iopub.status.idle": "2024-06-04T07:03:54.956208Z",
     "shell.execute_reply": "2024-06-04T07:03:54.954991Z"
    },
    "papermill": {
     "duration": 0.021979,
     "end_time": "2024-06-04T07:03:54.958928",
     "exception": false,
     "start_time": "2024-06-04T07:03:54.936949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is not available. Using CPU.\n"
     ]
    }
   ],
   "source": [
    "root = '/kaggle/input/pestvisiondata/pestvision/pestvision_data'\n",
    "synth_dset_paths = ['synthetic_data/DeepImageBlendingData/run3/RiceLeafs/images/train',\n",
    "             'synthetic_data/DeepImageBlendingData/run3/paddy-disease-classification/images/train',\n",
    "             'synthetic_data/Libcom_HarmonizationData_PCTNet/run1/RiceLeafs/images/train',\n",
    "             'synthetic_data/Libcom_HarmonizationData_PCTNet/run1/paddy-disease-classification/images/train']\n",
    "synth_dset_paths = [os.path.join(root,i) for i in synth_dset_paths]\n",
    "val_paths = [\"/\".join(i.split('/')[:-1]+['val']) for i in synth_dset_paths]\n",
    "real_paths = ['/kaggle/input/realpestdet/data/images/train']\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "feb56416",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:03:54.979000Z",
     "iopub.status.busy": "2024-06-04T07:03:54.977960Z",
     "iopub.status.idle": "2024-06-04T07:03:54.988374Z",
     "shell.execute_reply": "2024-06-04T07:03:54.987040Z"
    },
    "papermill": {
     "duration": 0.023205,
     "end_time": "2024-06-04T07:03:54.990918",
     "exception": false,
     "start_time": "2024-06-04T07:03:54.967713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AbstractPestDetection(ABC):\n",
    "    \"\"\"\n",
    "    Abstract class for pest detection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_model(self, model_path):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    # TODO: implement evaluate method\n",
    "    # @abstractmethod\n",
    "    # def evaluate(self):\n",
    "    #     pass\n",
    "\n",
    "\n",
    "class PestDetection_yolov8(AbstractPestDetection):\n",
    "    \"\"\"\n",
    "    YOLOv8 model for pest detection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device):\n",
    "        super().__init__(device)\n",
    "        self.model = None\n",
    "\n",
    "    def load_model(self, model_path=\"yolov8n.pt\"):\n",
    "        \"\"\"\n",
    "        Load the YOLOv8 model\n",
    "\n",
    "        Parameters:\n",
    "\n",
    "         model_path (str): path to the model checkpoint\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "    def train(self,**kwargs):\n",
    "\n",
    "        results = self.model.train(**kwargs)\n",
    "        self.model.val()\n",
    "\n",
    "        return results\n",
    "\n",
    "    # TODO: implment evaluate method\n",
    "    # def evaluate(self):\n",
    "    #     pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b31f97f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:03:55.010744Z",
     "iopub.status.busy": "2024-06-04T07:03:55.010341Z",
     "iopub.status.idle": "2024-06-04T07:03:55.017448Z",
     "shell.execute_reply": "2024-06-04T07:03:55.016073Z"
    },
    "papermill": {
     "duration": 0.020511,
     "end_time": "2024-06-04T07:03:55.020130",
     "exception": false,
     "start_time": "2024-06-04T07:03:54.999619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dsetconfig(train,val):\n",
    "\n",
    "    d_config = {\n",
    "        \"train\": train,\n",
    "        \"val\": val,\n",
    "\n",
    "        \"nc\": 102, # number of classes\n",
    "        \"names\": [str(i) for i in range(1,103)] \n",
    "    }\n",
    "    filename = 'data.yaml'\n",
    "    with open(filename, 'w') as file:\n",
    "        yaml.dump(d_config, file, default_flow_style=False)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c07a2c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:03:55.040404Z",
     "iopub.status.busy": "2024-06-04T07:03:55.039638Z",
     "iopub.status.idle": "2024-06-04T07:03:55.045925Z",
     "shell.execute_reply": "2024-06-04T07:03:55.044835Z"
    },
    "papermill": {
     "duration": 0.01888,
     "end_time": "2024-06-04T07:03:55.048210",
     "exception": false,
     "start_time": "2024-06-04T07:03:55.029330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(checkpoint,train,val,resume = False):\n",
    "    model = PestDetection_yolov8(device)\n",
    "    model.load_model(checkpoint)\n",
    "    results = model.train(data=make_dsetconfig(train,val), epochs=50, imgsz=512, save_period=10,batch=-1, plots=True, resume = resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0f818a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:03:55.067692Z",
     "iopub.status.busy": "2024-06-04T07:03:55.067299Z",
     "iopub.status.idle": "2024-06-04T07:03:55.078805Z",
     "shell.execute_reply": "2024-06-04T07:03:55.077661Z"
    },
    "papermill": {
     "duration": 0.024314,
     "end_time": "2024-06-04T07:03:55.081519",
     "exception": false,
     "start_time": "2024-06-04T07:03:55.057205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def convert_to_yolo_format(annotation_file,dest):\n",
    "    tree = ET.parse(annotation_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    \n",
    "    size = root.find('size')\n",
    "    image_width = int(size.find('width').text)\n",
    "    image_height = int(size.find('height').text)\n",
    "    \n",
    "    \n",
    "    for obj in root.iter('object'):\n",
    "        name = obj.find('name').text\n",
    "        bndbox = obj.find('bndbox')\n",
    "        \n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "        \n",
    "        \n",
    "        x_center = (xmin + xmax) / 2.0 / image_width\n",
    "        y_center = (ymin + ymax) / 2.0 / image_height\n",
    "        width = (xmax - xmin) / image_width\n",
    "        height = (ymax - ymin) / image_height\n",
    "        \n",
    "        yolo_format = f\"{name} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
    "        \n",
    "        \n",
    "        txt_filename = dest\n",
    "        with open(txt_filename, 'w') as txt_file:\n",
    "            txt_file.write(yolo_format + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1bd9fbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:03:55.100149Z",
     "iopub.status.busy": "2024-06-04T07:03:55.099730Z",
     "iopub.status.idle": "2024-06-04T07:03:55.105358Z",
     "shell.execute_reply": "2024-06-04T07:03:55.104266Z"
    },
    "papermill": {
     "duration": 0.017709,
     "end_time": "2024-06-04T07:03:55.107669",
     "exception": false,
     "start_time": "2024-06-04T07:03:55.089960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# annotations_path = '/kaggle/input/pestvisiondata/pestvision/pestvision_data/foreground_data/Detection_IP102/Annotations'\n",
    "# images_path = '/kaggle/input/pestvisiondata/pestvision/pestvision_data/foreground_data/Detection_IP102/JPEGImages'\n",
    "# label_path = 'data/labels/train/'\n",
    "# timage_path = 'data/images/train/'\n",
    "# if not os.path.isdir(label_path):\n",
    "#     os.makedirs(label_path)\n",
    "# if not os.path.isdir(timage_path):\n",
    "#     os.makedirs(timage_path)\n",
    "\n",
    "# i = 0\n",
    "# for filename in os.listdir(annotations_path):\n",
    "    \n",
    "#     if filename.endswith('.xml'):\n",
    "#         xml_file_path = os.path.join(annotations_path,filename)\n",
    "        \n",
    "#         convert_to_yolo_format(xml_file_path,os.path.join(label_path,filename.replace('.xml','.txt')))\n",
    "#         image = Image.open(os.path.join(images_path,filename.replace('.xml','.jpg')))\n",
    "#         image = image.resize((512,512))\n",
    "#         image.save(os.path.join(timage_path,filename.replace('.xml','.jpg')))\n",
    "#         i+=1\n",
    "# print('#################### completed:',i,'##############################')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ca81ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:03:55.126680Z",
     "iopub.status.busy": "2024-06-04T07:03:55.126142Z",
     "iopub.status.idle": "2024-06-04T07:03:55.131266Z",
     "shell.execute_reply": "2024-06-04T07:03:55.130200Z"
    },
    "papermill": {
     "duration": 0.017273,
     "end_time": "2024-06-04T07:03:55.133642",
     "exception": false,
     "start_time": "2024-06-04T07:03:55.116369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train(\"yolov8n.pt\",'/kaggle/input/realpestdet/data/images/train', val_paths[1], False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d740c9eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:03:55.153555Z",
     "iopub.status.busy": "2024-06-04T07:03:55.153117Z",
     "iopub.status.idle": "2024-06-04T07:03:55.175951Z",
     "shell.execute_reply": "2024-06-04T07:03:55.174853Z"
    },
    "papermill": {
     "duration": 0.036236,
     "end_time": "2024-06-04T07:03:55.178454",
     "exception": false,
     "start_time": "2024-06-04T07:03:55.142218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def segment(image):\n",
    "    \n",
    "    segment_size = 512\n",
    "    if min(image.shape[0], image.shape[1])<512:\n",
    "        segment_size = min(image.shape[0], image.shape[1])\n",
    "    increment = int(segment_size*(3/4))\n",
    "\n",
    "    images = []\n",
    "    pos = []\n",
    "    \n",
    "    i = 0\n",
    "    while i+segment_size<image.shape[0]:\n",
    "        j = 0\n",
    "        while j+segment_size<image.shape[1]:\n",
    "            images.append(image[i:i+segment_size, j:j+segment_size])\n",
    "            pos.append([i,i+segment_size, j,j+segment_size])\n",
    "            j+=increment\n",
    "        i+=increment\n",
    "    \n",
    "    i=0\n",
    "    j=0\n",
    "    while j+segment_size<image.shape[1]:\n",
    "        images.append(image[image.shape[0]-segment_size:image.shape[0], j:j+segment_size])\n",
    "        pos.append([image.shape[0]-segment_size,image.shape[0], j,j+segment_size])\n",
    "        j+=increment\n",
    "    while i+segment_size<image.shape[0]:\n",
    "        images.append(image[i:i+segment_size,image.shape[1]-segment_size:image.shape[1]])\n",
    "        pos.append([i,i+segment_size,image.shape[1]-segment_size,image.shape[1]])\n",
    "        i+=increment\n",
    "    \n",
    "    images.append(image[image.shape[0]-segment_size:image.shape[0],image.shape[1]-segment_size:image.shape[1]])\n",
    "    pos.append([image.shape[0]-segment_size,image.shape[0],image.shape[1]-segment_size,image.shape[1]])\n",
    "    \n",
    "    return images, pos, segment_size\n",
    "    \n",
    "        \n",
    "\n",
    "def segment_eval(model, image):\n",
    "    s_images, pos, sz = segment(image) \n",
    "    h,w = image.shape[0], image.shape[1]\n",
    "    \n",
    "    boxes = torch.empty((0,4),dtype = torch.int)\n",
    "    confs = torch.empty((0))\n",
    "    class_ids = torch.empty((0), dtype=torch.int)\n",
    "    \n",
    "    for sample_i, sample_pos in zip(s_images, pos):\n",
    "        results = model.predict(sample_i)[0]\n",
    "    \n",
    "        sample_boxes = results.boxes.xyxy.clone()\n",
    "        sample_boxes[:,0] = sample_boxes[:,0]+sample_pos[2]\n",
    "        sample_boxes[:,1] = sample_boxes[:,1]+sample_pos[0]\n",
    "        sample_boxes[:,2] = sample_boxes[:,2]+sample_pos[2]\n",
    "        sample_boxes[:,3] = sample_boxes[:,3]+sample_pos[0]\n",
    "        boxes = torch.cat((boxes,sample_boxes),dim=0)\n",
    "        \n",
    "        sample_conf = results.boxes.conf\n",
    "        confs = torch.cat((confs,sample_conf),dim=0)\n",
    "        \n",
    "        sample_cids = results.boxes.cls\n",
    "        class_ids = torch.cat((class_ids, sample_cids),dim=0)\n",
    "    keep_indices = torch.ops.torchvision.nms(boxes, confs, 0.2)\n",
    "        \n",
    "    return boxes.to(torch.int)[keep_indices], confs[keep_indices], class_ids.to(torch.int)[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c90c187",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:03:55.197206Z",
     "iopub.status.busy": "2024-06-04T07:03:55.196802Z",
     "iopub.status.idle": "2024-06-04T07:03:55.206020Z",
     "shell.execute_reply": "2024-06-04T07:03:55.204770Z"
    },
    "papermill": {
     "duration": 0.021575,
     "end_time": "2024-06-04T07:03:55.208523",
     "exception": false,
     "start_time": "2024-06-04T07:03:55.186948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_image_with_boxes(image, boxes, confidences, class_ids, class_names):\n",
    "    \"\"\"\n",
    "    Plot image with bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "    - image: numpy array representing the image\n",
    "    - boxes: list of bounding boxes in xyxy format\n",
    "    - confidences: list of confidence scores\n",
    "    - class_ids: list of class IDs\n",
    "    - class_names: list of class names\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "\n",
    "    for box, confidence, class_id in zip(boxes, confidences, class_ids):\n",
    "        x1, y1, x2, y2 = box\n",
    "        box_width = x2 - x1\n",
    "        box_height = y2 - y1\n",
    "        \n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle((x1, y1), box_width, box_height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add class label and confidence score\n",
    "        class_name = class_names[class_id]\n",
    "        ax.text(x1, y1, f'{class_name} {confidence:.2f}', color='r', fontsize=8, backgroundcolor='none')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c455cda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:03:55.227672Z",
     "iopub.status.busy": "2024-06-04T07:03:55.227234Z",
     "iopub.status.idle": "2024-06-04T07:03:55.232650Z",
     "shell.execute_reply": "2024-06-04T07:03:55.231484Z"
    },
    "papermill": {
     "duration": 0.018447,
     "end_time": "2024-06-04T07:03:55.235641",
     "exception": false,
     "start_time": "2024-06-04T07:03:55.217194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# img = imageio.imread('/kaggle/input/pestvisiondata/images/images/c30ed669-c9be-4618-b2a8-eaadfc27d315.jpg')\n",
    "# model = PestDetection_yolov8(device)\n",
    "# model.load_model('/kaggle/input/yolo/other/exp1/11/last_syth_real.pt')\n",
    "# boxes, confs, class_ids = segment_eval(model.model, img)\n",
    "# plot_image_with_boxes(img,boxes,confs,class_ids,[str(i) for i in range(1,103)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12f1a164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:03:55.254657Z",
     "iopub.status.busy": "2024-06-04T07:03:55.254126Z",
     "iopub.status.idle": "2024-06-04T07:03:55.484602Z",
     "shell.execute_reply": "2024-06-04T07:03:55.483446Z"
    },
    "papermill": {
     "duration": 0.243872,
     "end_time": "2024-06-04T07:03:55.488105",
     "exception": false,
     "start_time": "2024-06-04T07:03:55.244233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['id', 'name', 'supercategory'])\n",
      "dict_keys(['area', 'bbox', 'category_id', 'id', 'image_id', 'iscrowd', 'segmentation'])\n",
      "dict_keys(['file_name', 'id', 'width', 'height'])\n",
      "[1765]\n",
      "[[138.0, 115.0, 151.0, 84.0], [291.0, 136.0, 138.0, 65.0]]\n"
     ]
    }
   ],
   "source": [
    "train_path = '/kaggle/input/pest-new-real/Pest Data-3/train2017'\n",
    "anno_path = '/kaggle/input/pest-new-real/Pest Data-3/annotations/instances_train2017.json'\n",
    "\n",
    "with open(anno_path, 'r') as f:\n",
    "    anno = json.load(f)\n",
    "    \n",
    "print(anno['categories'][0].keys())\n",
    "print(anno['annotations'][0].keys())\n",
    "print(anno['images'][0].keys())\n",
    "print([i['id'] for i in anno['images'] if i['file_name']=='061.jpg'])\n",
    "print([j['bbox'] for j in anno['annotations'] if j['image_id']==1765])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89d67ad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:03:55.508236Z",
     "iopub.status.busy": "2024-06-04T07:03:55.507764Z",
     "iopub.status.idle": "2024-06-04T07:06:11.660388Z",
     "shell.execute_reply": "2024-06-04T07:06:11.659124Z"
    },
    "papermill": {
     "duration": 136.175354,
     "end_time": "2024-06-04T07:06:11.672203",
     "exception": false,
     "start_time": "2024-06-04T07:03:55.496849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful: 2496\n"
     ]
    }
   ],
   "source": [
    "image_p = './data1/images/train'\n",
    "label_p = './data1/labels/train'\n",
    "\n",
    "if not os.path.exists(image_p):\n",
    "    os.makedirs(image_p)\n",
    "if not os.path.exists(label_p):\n",
    "    os.makedirs(label_p)\n",
    "\n",
    "# print(len(os.listdir(train_path)))\n",
    "cnt = 0\n",
    "for i in anno['images']:\n",
    "    if os.path.isfile(os.path.join(train_path,i['file_name'])):\n",
    "        img = Image.open(os.path.join(train_path,i['file_name']))\n",
    "        img.save(os.path.join(image_p,i['file_name']))\n",
    "\n",
    "        with open(os.path.join(label_p,i['file_name'].split('.')[0]+'.txt'), 'w') as f:\n",
    "            i_anno = [j for j in anno['annotations'] if j['image_id']==i['id']]\n",
    "            for j in i_anno:\n",
    "                cate = 0\n",
    "                x = (j['bbox'][0]+i['width']/2)/i['width']\n",
    "                y = (j['bbox'][1]+i['height']/2)/i['height']\n",
    "                w = j['bbox'][2]/i['width']\n",
    "                h = j['bbox'][3]/i['height']\n",
    "                f.write(' '.join(map(str,[cate,x,y,w,h]))+'\\n')\n",
    "        cnt+=1\n",
    "print('Successful:',cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "638c2e2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:06:11.700910Z",
     "iopub.status.busy": "2024-06-04T07:06:11.700264Z",
     "iopub.status.idle": "2024-06-04T07:06:11.726214Z",
     "shell.execute_reply": "2024-06-04T07:06:11.725028Z"
    },
    "papermill": {
     "duration": 0.045092,
     "end_time": "2024-06-04T07:06:11.729212",
     "exception": false,
     "start_time": "2024-06-04T07:06:11.684120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def resize_and_pad(img, target_size):\n",
    "    h, w = img.shape[:2]\n",
    "    scale = min(target_size / h, target_size / w)\n",
    "    nh, nw = int(h * scale), int(w * scale)\n",
    "    img_resized = cv2.resize(img, (nw, nh))\n",
    "    bot_pad = target_size - nh\n",
    "    right_pad = target_size - nw\n",
    "    img_padded = cv2.copyMakeBorder(img_resized, 0, bot_pad, 0, right_pad, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "    return img_padded, scale, bot_pad, right_pad\n",
    "\n",
    "def adjust_labels(labels, scale, bot_pad, right_pad, cell_size):\n",
    "    adjusted_labels = []\n",
    "    \n",
    "    for label in labels:\n",
    "        cls, cx, cy, w, h = label\n",
    "        cx = (cx*(cell_size-right_pad))/cell_size\n",
    "        cy = (cy*(cell_size-bot_pad))/cell_size\n",
    "        w = (w*(cell_size-right_pad))/cell_size\n",
    "        h = (h*(cell_size-bot_pad))/cell_size\n",
    "        adjusted_labels.append([cls, cx, cy , w , h])\n",
    "    return adjusted_labels\n",
    "\n",
    "def fuse(n, img_paths, label_paths, dest_image, dest_label):\n",
    "    if not os.path.exists(dest_image):\n",
    "        os.makedirs(dest_image)\n",
    "    if not os.path.exists(dest_label):\n",
    "        os.makedirs(dest_label)\n",
    "    target_size = 512\n",
    "    cell_size = target_size // n\n",
    "    \n",
    "    img_files = sorted([os.path.join(p, f) for p in img_paths for f in os.listdir(p) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    label_files = sorted([os.path.join(p, f) for p in label_paths for f in os.listdir(p) if f.endswith('.txt')])\n",
    "    \n",
    "    \n",
    "    assert len(img_files) == len(label_files), \"Number of image and label files should be the same\"\n",
    "    \n",
    "#     for i in range(len(img_files)):\n",
    "    for i in range(100):\n",
    "        img_fused = np.zeros((target_size, target_size, 3), dtype=np.uint8)\n",
    "        all_labels = []\n",
    "        \n",
    "        selected_indices = random.sample(range(len(img_files)), n*n)\n",
    "        idx = 0\n",
    "        \n",
    "        for row in range(n):\n",
    "            for col in range(n):\n",
    "                img_path = img_files[selected_indices[idx]]\n",
    "                label_path = label_files[selected_indices[idx]]\n",
    "                \n",
    "                img = cv2.imread(img_path)\n",
    "                with open(label_path, 'r') as f:\n",
    "                    labels = [list(map(float, line.strip().split())) for line in f.readlines()]\n",
    "                \n",
    "                img_resized, scale, top_pad, right_pad = resize_and_pad(img, cell_size)\n",
    "                \n",
    "                start_y, start_x = row * cell_size, col * cell_size\n",
    "                img_fused[start_y:start_y + cell_size, start_x:start_x + cell_size] = img_resized[:cell_size, :cell_size]\n",
    "                \n",
    "                adjusted_labels = adjust_labels(labels, scale, top_pad, right_pad, cell_size)\n",
    "                for label in adjusted_labels:\n",
    "                    cls, cx, cy, w, h = label\n",
    "                    cx = (cx * cell_size + start_x) / target_size\n",
    "                    cy = (cy * cell_size + start_y) / target_size\n",
    "                    w /= n\n",
    "                    h /= n\n",
    "                    all_labels.append([cls, cx, cy, w, h])\n",
    "                \n",
    "                idx += 1\n",
    "        \n",
    "        img_filename = os.path.join(dest_image, f'fused_{i}.jpg')\n",
    "        cv2.imwrite(img_filename, img_fused)\n",
    "        \n",
    "        label_filename = os.path.join(dest_label, f'fused_{i}.txt')\n",
    "        with open(label_filename, 'w') as f:\n",
    "            for label in all_labels:\n",
    "                f.write(' '.join(map(str, label)) + '\\n')\n",
    "\n",
    "# Example usage:\n",
    "# fuse(2, ['/kaggle/input/realpestdet/data/images/train'], ['/kaggle/input/realpestdet/data/labels/train'], 'data/images/train', 'data/labels/train')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9eea8a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-04T07:06:11.749428Z",
     "iopub.status.busy": "2024-06-04T07:06:11.749020Z",
     "iopub.status.idle": "2024-06-04T07:06:11.754766Z",
     "shell.execute_reply": "2024-06-04T07:06:11.753353Z"
    },
    "papermill": {
     "duration": 0.019179,
     "end_time": "2024-06-04T07:06:11.757519",
     "exception": false,
     "start_time": "2024-06-04T07:06:11.738340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open('data/labels/train/fused_33.txt','r') as f:\n",
    "#     data = f.readlines()\n",
    "# print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5067045,
     "sourceId": 8492734,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5139886,
     "sourceId": 8592563,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5095802,
     "sourceId": 8593433,
     "sourceType": "datasetVersion"
    },
    {
     "modelInstanceId": 46883,
     "sourceId": 57064,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 46883,
     "sourceId": 57345,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 46883,
     "sourceId": 57563,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 46883,
     "sourceId": 57573,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 46883,
     "sourceId": 58338,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 169.286283,
   "end_time": "2024-06-04T07:06:14.244599",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-04T07:03:24.958316",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
