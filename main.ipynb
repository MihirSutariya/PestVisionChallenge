{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99c7c5a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T16:33:15.183132Z",
     "iopub.status.busy": "2024-06-05T16:33:15.182799Z",
     "iopub.status.idle": "2024-06-05T16:33:30.125466Z",
     "shell.execute_reply": "2024-06-05T16:33:30.124304Z"
    },
    "papermill": {
     "duration": 14.952882,
     "end_time": "2024-06-05T16:33:30.127828",
     "exception": false,
     "start_time": "2024-06-05T16:33:15.174946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ultralytics\r\n",
      "  Downloading ultralytics-8.2.28-py3-none-any.whl.metadata (41 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (3.7.5)\r\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.9.0.80)\r\n",
      "Requirement already satisfied: pillow>=7.1.2 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.5.0)\r\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (6.0.1)\r\n",
      "Requirement already satisfied: requests>=2.23.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.31.0)\r\n",
      "Requirement already satisfied: scipy>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (1.11.4)\r\n",
      "Requirement already satisfied: torch>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.2)\r\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.16.2)\r\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (4.66.1)\r\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from ultralytics) (5.9.3)\r\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from ultralytics) (9.0.0)\r\n",
      "Requirement already satisfied: pandas>=1.1.4 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (2.1.4)\r\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from ultralytics) (0.12.2)\r\n",
      "Collecting ultralytics-thop>=0.2.5 (from ultralytics)\r\n",
      "  Downloading ultralytics_thop-0.2.7-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\r\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.0)\r\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\r\n",
      "Requirement already satisfied: numpy<2,>=1.20 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (1.26.4)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (21.3)\r\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\r\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.8.0->ultralytics) (2024.2.0)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\r\n",
      "Downloading ultralytics-8.2.28-py3-none-any.whl (779 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.6/779.6 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ultralytics_thop-0.2.7-py3-none-any.whl (25 kB)\r\n",
      "Installing collected packages: ultralytics-thop, ultralytics\r\n",
      "Successfully installed ultralytics-8.2.28 ultralytics-thop-0.2.7\r\n"
     ]
    }
   ],
   "source": [
    "# !conda env create -f /kaggle/input/condaenv/environment.yml\n",
    "# !conda init\n",
    "# !conda activate pestvision\n",
    "# !wget -P /kaggle/input/ https://storage.googleapis.com/npss-pestvision-data/pestvision_data.zip\n",
    "!pip install ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33d05a95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T16:33:30.144843Z",
     "iopub.status.busy": "2024-06-05T16:33:30.144489Z",
     "iopub.status.idle": "2024-06-05T16:33:37.611494Z",
     "shell.execute_reply": "2024-06-05T16:33:37.610440Z"
    },
    "papermill": {
     "duration": 7.478658,
     "end_time": "2024-06-05T16:33:37.614536",
     "exception": false,
     "start_time": "2024-06-05T16:33:30.135878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m This integration is tested and supported for ultralytics v8.0.238 and below.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m             Please report any issues to https://github.com/wandb/wandb/issues with the tag `yolov8`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "import imageio.v3 as imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import json\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from ultralytics import YOLO\n",
    "import wandb\n",
    "from wandb.integration.ultralytics import add_wandb_callback\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from glob import glob\n",
    "# from natsort import natsorted\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import xml.etree.ElementTree as ET\n",
    "from typing import List, Tuple, Optional, Callable, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec58f036",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T16:33:37.637424Z",
     "iopub.status.busy": "2024-06-05T16:33:37.636967Z",
     "iopub.status.idle": "2024-06-05T16:33:37.695674Z",
     "shell.execute_reply": "2024-06-05T16:33:37.694808Z"
    },
    "papermill": {
     "duration": 0.072542,
     "end_time": "2024-06-05T16:33:37.698156",
     "exception": false,
     "start_time": "2024-06-05T16:33:37.625614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "root = '/kaggle/input/pestvisiondata/pestvision/pestvision_data'\n",
    "synth_dset_paths = ['synthetic_data/DeepImageBlendingData/run3/RiceLeafs/images/train',\n",
    "             'synthetic_data/DeepImageBlendingData/run3/paddy-disease-classification/images/train',\n",
    "             'synthetic_data/Libcom_HarmonizationData_PCTNet/run1/RiceLeafs/images/train',\n",
    "             'synthetic_data/Libcom_HarmonizationData_PCTNet/run1/paddy-disease-classification/images/train']\n",
    "synth_dset_paths = [os.path.join(root,i) for i in synth_dset_paths]\n",
    "val_paths = [\"/\".join(i.split('/')[:-1]+['val']) for i in synth_dset_paths]\n",
    "real_paths = ['/kaggle/input/realpestdet/data/images/train']\n",
    "\n",
    "rval_paths = ['/kaggle/input/pestvision-val/real_dset/images/val']\n",
    "cust_paths = ['/kaggle/input/realpestdet/data/fuse2/images/train','/kaggle/input/realpestdet/data/fuse4/images/train','/kaggle/input/online-ip102/online_real/images/train','/kaggle/input/online-ip102/ip102/images/train']\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(\"CUDA is available. Using GPU.\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38dea0a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T16:33:37.715049Z",
     "iopub.status.busy": "2024-06-05T16:33:37.714745Z",
     "iopub.status.idle": "2024-06-05T16:33:37.723488Z",
     "shell.execute_reply": "2024-06-05T16:33:37.722560Z"
    },
    "papermill": {
     "duration": 0.019531,
     "end_time": "2024-06-05T16:33:37.725464",
     "exception": false,
     "start_time": "2024-06-05T16:33:37.705933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AbstractPestDetection(ABC):\n",
    "    \"\"\"\n",
    "    Abstract class for pest detection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_model(self, model_path):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def train(self):\n",
    "        pass\n",
    "\n",
    "    # TODO: implement evaluate method\n",
    "    # @abstractmethod\n",
    "    # def evaluate(self):\n",
    "    #     pass\n",
    "\n",
    "\n",
    "class PestDetection_yolov8(AbstractPestDetection):\n",
    "    \"\"\"\n",
    "    YOLOv8 model for pest detection\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, device):\n",
    "        super().__init__(device)\n",
    "        self.model = None\n",
    "\n",
    "    def load_model(self, model_path=\"yolov8n.pt\"):\n",
    "        \"\"\"\n",
    "        Load the YOLOv8 model\n",
    "\n",
    "        Parameters:\n",
    "\n",
    "         model_path (str): path to the model checkpoint\n",
    "        \"\"\"\n",
    "        self.model = YOLO(model_path)\n",
    "\n",
    "    def train(self,**kwargs):\n",
    "\n",
    "        results = self.model.train(**kwargs)\n",
    "        self.model.val()\n",
    "\n",
    "        return results\n",
    "\n",
    "    # TODO: implment evaluate method\n",
    "    # def evaluate(self):\n",
    "    #     pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91b2b655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T16:33:37.741811Z",
     "iopub.status.busy": "2024-06-05T16:33:37.741385Z",
     "iopub.status.idle": "2024-06-05T16:33:37.747812Z",
     "shell.execute_reply": "2024-06-05T16:33:37.746907Z"
    },
    "papermill": {
     "duration": 0.016848,
     "end_time": "2024-06-05T16:33:37.749885",
     "exception": false,
     "start_time": "2024-06-05T16:33:37.733037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_dsetconfig(train,val):\n",
    "\n",
    "    d_config = {\n",
    "        \"train\": train,\n",
    "        \"val\": val,\n",
    "\n",
    "        \"nc\": 102, # number of classes\n",
    "        \"names\": [str(i) for i in range(102)] \n",
    "    }\n",
    "    filename = 'data.yaml'\n",
    "    with open(filename, 'w') as file:\n",
    "        yaml.dump(d_config, file, default_flow_style=False)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "645a7953",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T16:33:37.766151Z",
     "iopub.status.busy": "2024-06-05T16:33:37.765346Z",
     "iopub.status.idle": "2024-06-05T16:33:37.771610Z",
     "shell.execute_reply": "2024-06-05T16:33:37.770619Z"
    },
    "papermill": {
     "duration": 0.016757,
     "end_time": "2024-06-05T16:33:37.773858",
     "exception": false,
     "start_time": "2024-06-05T16:33:37.757101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(checkpoint,train,val,resume = False):\n",
    "    model = PestDetection_yolov8(device)\n",
    "    model.load_model(checkpoint)\n",
    "    results = model.train(data=make_dsetconfig(train,val), epochs=25, imgsz=512, save_period=10,batch=-1, plots=True, resume = resume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "949652aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T16:33:37.789732Z",
     "iopub.status.busy": "2024-06-05T16:33:37.789444Z",
     "iopub.status.idle": "2024-06-05T16:33:37.798517Z",
     "shell.execute_reply": "2024-06-05T16:33:37.797547Z"
    },
    "papermill": {
     "duration": 0.019392,
     "end_time": "2024-06-05T16:33:37.800540",
     "exception": false,
     "start_time": "2024-06-05T16:33:37.781148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "def convert_to_yolo_format(annotation_file,dest):\n",
    "    tree = ET.parse(annotation_file)\n",
    "    root = tree.getroot()\n",
    "    \n",
    "    \n",
    "    size = root.find('size')\n",
    "    image_width = int(size.find('width').text)\n",
    "    image_height = int(size.find('height').text)\n",
    "    \n",
    "    \n",
    "    for obj in root.iter('object'):\n",
    "        name = obj.find('name').text\n",
    "        bndbox = obj.find('bndbox')\n",
    "        \n",
    "        xmin = int(bndbox.find('xmin').text)\n",
    "        ymin = int(bndbox.find('ymin').text)\n",
    "        xmax = int(bndbox.find('xmax').text)\n",
    "        ymax = int(bndbox.find('ymax').text)\n",
    "        \n",
    "        \n",
    "        x_center = (xmin + xmax) / 2.0 / image_width\n",
    "        y_center = (ymin + ymax) / 2.0 / image_height\n",
    "        width = (xmax - xmin) / image_width\n",
    "        height = (ymax - ymin) / image_height\n",
    "        \n",
    "        yolo_format = f\"{name} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\"\n",
    "        \n",
    "        \n",
    "        txt_filename = dest\n",
    "        with open(txt_filename, 'w') as txt_file:\n",
    "            txt_file.write(yolo_format + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63005474",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T16:33:37.817072Z",
     "iopub.status.busy": "2024-06-05T16:33:37.816720Z",
     "iopub.status.idle": "2024-06-05T16:33:37.822008Z",
     "shell.execute_reply": "2024-06-05T16:33:37.821110Z"
    },
    "papermill": {
     "duration": 0.01594,
     "end_time": "2024-06-05T16:33:37.824047",
     "exception": false,
     "start_time": "2024-06-05T16:33:37.808107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# annotations_path = '/kaggle/input/pestvisiondata/pestvision/pestvision_data/foreground_data/Detection_IP102/Annotations'\n",
    "# images_path = '/kaggle/input/pestvisiondata/pestvision/pestvision_data/foreground_data/Detection_IP102/JPEGImages'\n",
    "# label_path = 'data/labels/train/'\n",
    "# timage_path = 'data/images/train/'\n",
    "# if not os.path.isdir(label_path):\n",
    "#     os.makedirs(label_path)\n",
    "# if not os.path.isdir(timage_path):\n",
    "#     os.makedirs(timage_path)\n",
    "\n",
    "# i = 0\n",
    "# for filename in os.listdir(annotations_path):\n",
    "    \n",
    "#     if filename.endswith('.xml'):\n",
    "#         xml_file_path = os.path.join(annotations_path,filename)\n",
    "        \n",
    "#         convert_to_yolo_format(xml_file_path,os.path.join(label_path,filename.replace('.xml','.txt')))\n",
    "#         image = Image.open(os.path.join(images_path,filename.replace('.xml','.jpg')))\n",
    "#         image = image.resize((512,512))\n",
    "#         image.save(os.path.join(timage_path,filename.replace('.xml','.jpg')))\n",
    "#         i+=1\n",
    "# print('#################### completed:',i,'##############################')\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb87dc82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T16:33:37.841073Z",
     "iopub.status.busy": "2024-06-05T16:33:37.840732Z",
     "iopub.status.idle": "2024-06-05T20:20:55.753121Z",
     "shell.execute_reply": "2024-06-05T20:20:55.751940Z"
    },
    "papermill": {
     "duration": 13637.923789,
     "end_time": "2024-06-05T20:20:55.755387",
     "exception": false,
     "start_time": "2024-06-05T16:33:37.831598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6.23M/6.23M [00:00<00:00, 142MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.28 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=data.yaml, epochs=25, time=None, patience=100, batch=-1, imgsz=512, save=True, save_period=10, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 755k/755k [00:00<00:00, 41.1MB/s]\n",
      "2024-06-05 16:33:41,797\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2024-06-05 16:33:43,220\tINFO util.py:124 -- Outdated packages:\n",
      "  ipywidgets==7.7.1 found, needs ipywidgets>=8\n",
      "Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=102\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1087210  ultralytics.nn.modules.head.Detect           [102, [64, 128, 256]]         \n",
      "Model summary: 225 layers, 3346746 parameters, 3346730 gradients, 9.7 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.6\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to \u001b[1m`offline`\u001b[0m in this directory.  \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb online`\u001b[0m or set \u001b[1mWANDB_MODE=online\u001b[0m to enable cloud syncing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mComputing optimal batch size for imgsz=512\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mCUDA:0 (Tesla P100-PCIE-16GB) 15.89G total, 0.10G reserved, 0.06G allocated, 15.73G free\n",
      "      Params      GFLOPs  GPU_mem (GB)  forward (ms) backward (ms)                   input                  output\n",
      "     3346746       6.225         0.168         29.98         56.17        (1, 3, 512, 512)                    list\n",
      "     3346746       12.45         0.247         18.56         32.39        (2, 3, 512, 512)                    list\n",
      "     3346746        24.9         0.440         18.98          86.1        (4, 3, 512, 512)                    list\n",
      "     3346746        49.8         0.772         19.32         31.99        (8, 3, 512, 512)                    list\n",
      "     3346746        99.6         2.959         26.75         62.01       (16, 3, 512, 512)                    list\n",
      "\u001b[34m\u001b[1mAutoBatch: \u001b[0mUsing batch-size 52 for CUDA:0 9.54G/15.89G (60%) ✅\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /kaggle/input/pestvisiondata/pestvision/pestvision_data/synthetic_data/DeepImageBlendingData/run3/RiceLeafs/labels/train... 55966 images, 3572 backgrounds, 0 corrupt: 100%|██████████| 59529/59529 [05:05<00:00, 195.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/pestvisiondata/pestvision/pestvision_data/synthetic_data/DeepImageBlendingData/run3/RiceLeafs/labels is not writeable, cache not saved.\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/pestvision-val/real_dset/labels/val... 21 images, 1 backgrounds, 0 corrupt: 100%|██████████| 21/21 [00:00<00:00, 170.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/pestvision-val/real_dset/labels is not writeable, cache not saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.00040625000000000004), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n",
      "Image sizes 512 train, 512 val\n",
      "Using 4 dataloader workers\n",
      "Logging results to \u001b[1mruns/detect/train\u001b[0m\n",
      "Starting training for 25 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/25      7.12G      1.688      2.858      1.427        374        512: 100%|██████████| 1145/1145 [08:58<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0245     0.0366     0.0136    0.00394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       2/25      7.06G       1.52      2.089       1.33        404        512: 100%|██████████| 1145/1145 [08:58<00:00,  2.13it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0346     0.0157     0.0111    0.00266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       3/25      7.06G      1.529      2.015      1.334        424        512: 100%|██████████| 1145/1145 [09:00<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191   0.000859     0.0105   0.000469   0.000187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       4/25      7.06G      1.506      1.901      1.322        383        512: 100%|██████████| 1145/1145 [08:59<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0114     0.0209    0.00604    0.00166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       5/25      7.06G      1.445      1.748      1.281        397        512: 100%|██████████| 1145/1145 [08:51<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191    0.00866     0.0105    0.00395    0.00166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       6/25      7.06G      1.399      1.659      1.252        323        512: 100%|██████████| 1145/1145 [08:43<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0127     0.0209    0.00732    0.00197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       7/25      7.06G      1.362        1.6       1.23        401        512: 100%|██████████| 1145/1145 [08:46<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0203     0.0157     0.0121    0.00452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       8/25      7.06G      1.329      1.552      1.213        358        512: 100%|██████████| 1145/1145 [08:45<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0113     0.0157     0.0062    0.00307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       9/25      7.06G      1.302      1.518      1.198        352        512: 100%|██████████| 1145/1145 [08:54<00:00,  2.14it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0185     0.0209    0.00992    0.00395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      10/25      7.06G      1.277      1.482      1.183        358        512: 100%|██████████| 1145/1145 [08:51<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191      0.019     0.0209     0.0103    0.00436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      11/25      7.06G      1.257      1.463      1.172        322        512: 100%|██████████| 1145/1145 [08:46<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0169     0.0157    0.00884    0.00407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      12/25      7.06G      1.238      1.441       1.16        328        512: 100%|██████████| 1145/1145 [08:43<00:00,  2.19it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0213     0.0209     0.0111    0.00469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      13/25      7.06G      1.215      1.416      1.151        345        512: 100%|██████████| 1145/1145 [08:49<00:00,  2.16it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0167     0.0157    0.00856    0.00399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      14/25      7.06G      1.197      1.394       1.14        393        512: 100%|██████████| 1145/1145 [08:52<00:00,  2.15it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0155     0.0157    0.00819    0.00353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      15/25      7.06G      1.181      1.381      1.133        346        512: 100%|██████████| 1145/1145 [09:01<00:00,  2.12it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0168     0.0157    0.00907    0.00388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      16/25      6.94G      1.135      1.325       1.15        233        512: 100%|██████████| 1145/1145 [08:44<00:00,  2.18it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191      0.023     0.0209     0.0123    0.00458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      17/25      6.94G      1.117      1.304      1.139        199        512: 100%|██████████| 1145/1145 [08:37<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0244     0.0209     0.0129     0.0045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      18/25      6.94G      1.101      1.284      1.131        232        512: 100%|██████████| 1145/1145 [08:38<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0204     0.0157     0.0109     0.0033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      19/25      6.94G      1.083      1.264      1.121        247        512: 100%|██████████| 1145/1145 [08:35<00:00,  2.22it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  2.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0199     0.0157     0.0108    0.00326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      20/25      6.94G      1.065      1.242      1.112        191        512: 100%|██████████| 1145/1145 [08:38<00:00,  2.21it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0144     0.0105    0.00799    0.00315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      21/25      6.94G      1.052      1.228      1.104        229        512: 100%|██████████| 1145/1145 [08:30<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0149     0.0105    0.00832    0.00327\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      22/25      6.94G      1.034      1.213      1.096        299        512: 100%|██████████| 1145/1145 [08:18<00:00,  2.30it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0224     0.0157     0.0121    0.00368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      23/25      6.94G      1.018      1.192      1.089        235        512: 100%|██████████| 1145/1145 [08:27<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0214     0.0157     0.0117    0.00398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      24/25      6.94G      1.002      1.176      1.081        270        512: 100%|██████████| 1145/1145 [08:30<00:00,  2.24it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0146     0.0105    0.00827    0.00369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      25/25      6.95G      0.989      1.164      1.077        229        512: 100%|██████████| 1145/1145 [08:28<00:00,  2.25it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0145     0.0105    0.00814    0.00364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "25 epochs completed in 3.658 hours.\n",
      "Optimizer stripped from runs/detect/train/weights/last.pt, 6.9MB\n",
      "Optimizer stripped from runs/detect/train/weights/best.pt, 6.9MB\n",
      "\n",
      "Validating runs/detect/train/weights/best.pt...\n",
      "Ultralytics YOLOv8.2.28 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "Model summary (fused): 168 layers, 3341330 parameters, 0 gradients, 9.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:00<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191     0.0233     0.0209     0.0124    0.00462\n",
      "                     0         20        191     0.0233     0.0209     0.0124    0.00462\n",
      "Speed: 0.1ms preprocess, 1.8ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 ▃▆██▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 ▃▆██▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 ▃▆██▇▇▇▆▆▆▅▅▅▅▄▄▄▃▃▃▂▂▂▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) █▇▁▄▃▅▇▄▆▆▅▇▅▅▆▇█▇▆▅▅▇▇▅▇\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) ▇▅▁▃▃▄█▅▇▇▇█▇▆▇██▆▆▆▆▆▇▆█\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) ▆█▁▃▃▃▅▃▅▅▄▅▄▄▄▆▆▅▅▄▄▅▅▄▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) █▂▁▄▁▄▂▂▄▄▂▄▂▂▂▄▄▂▂▁▁▂▂▁▄\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) ▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss █▆▆▆▆▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss █▅▅▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss █▆▆▆▅▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▁▁\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss ▁▂▆▇▆▇▇▆▇▇▇▇▇▇▇▇█████████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss ▁▁▂▃▅▅▅▅▅▆▆▇▇▇▇▇▇▇▇▇█████\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss ▁▁▅█▆▆▆▅▅▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg0 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg1 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                  lr/pg2 0.0005\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        metrics/mAP50(B) 0.01238\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:     metrics/mAP50-95(B) 0.00462\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision(B) 0.02326\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall(B) 0.02094\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            model/GFLOPs 9.726\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:        model/parameters 3346746\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: model/speed_PyTorch(ms) 13.987\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/box_loss 0.98901\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/cls_loss 1.16367\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:          train/dfl_loss 1.07719\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/box_loss 4.69651\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/cls_loss 6.37533\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            val/dfl_loss 3.79993\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[1mwandb sync /kaggle/working/wandb/offline-run-20240605_163355-bi98528b\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/offline-run-20240605_163355-bi98528b/logs\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.28 🚀 Python-3.10.13 torch-2.1.2 CUDA:0 (Tesla P100-PCIE-16GB, 16276MiB)\n",
      "Model summary (fused): 168 layers, 3341330 parameters, 0 gradients, 9.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /kaggle/input/pestvision-val/real_dset/labels/val... 21 images, 1 backgrounds, 0 corrupt: 100%|██████████| 21/21 [00:00<00:00, 802.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mWARNING ⚠️ Cache directory /kaggle/input/pestvision-val/real_dset/labels is not writeable, cache not saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         21        191      0.023     0.0209     0.0123    0.00491\n",
      "                     0         20        191      0.023     0.0209     0.0123    0.00491\n",
      "Speed: 0.1ms preprocess, 9.1ms inference, 0.0ms loss, 2.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns/detect/train2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train(\"yolov8n.pt\",['/kaggle/input/realpestdet/data/fuse2/images/train','/kaggle/input/realpestdet/data/fuse4/images/train']+synth_dset_paths, rval_paths, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f8cf4a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T20:21:06.090111Z",
     "iopub.status.busy": "2024-06-05T20:21:06.088859Z",
     "iopub.status.idle": "2024-06-05T20:21:06.121165Z",
     "shell.execute_reply": "2024-06-05T20:21:06.120287Z"
    },
    "papermill": {
     "duration": 5.156968,
     "end_time": "2024-06-05T20:21:06.123215",
     "exception": false,
     "start_time": "2024-06-05T20:21:00.966247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def segment(image):\n",
    "    \n",
    "    segment_size = 512\n",
    "    if min(image.shape[0], image.shape[1])<512:\n",
    "        segment_size = min(image.shape[0], image.shape[1])\n",
    "    increment = int(segment_size*(3/4))\n",
    "\n",
    "    images = []\n",
    "    pos = []\n",
    "    \n",
    "    i = 0\n",
    "    while i+segment_size<image.shape[0]:\n",
    "        j = 0\n",
    "        while j+segment_size<image.shape[1]:\n",
    "            images.append(image[i:i+segment_size, j:j+segment_size])\n",
    "            pos.append([i,i+segment_size, j,j+segment_size])\n",
    "            j+=increment\n",
    "        i+=increment\n",
    "    \n",
    "    i=0\n",
    "    j=0\n",
    "    while j+segment_size<image.shape[1]:\n",
    "        images.append(image[image.shape[0]-segment_size:image.shape[0], j:j+segment_size])\n",
    "        pos.append([image.shape[0]-segment_size,image.shape[0], j,j+segment_size])\n",
    "        j+=increment\n",
    "    while i+segment_size<image.shape[0]:\n",
    "        images.append(image[i:i+segment_size,image.shape[1]-segment_size:image.shape[1]])\n",
    "        pos.append([i,i+segment_size,image.shape[1]-segment_size,image.shape[1]])\n",
    "        i+=increment\n",
    "    \n",
    "    images.append(image[image.shape[0]-segment_size:image.shape[0],image.shape[1]-segment_size:image.shape[1]])\n",
    "    pos.append([image.shape[0]-segment_size,image.shape[0],image.shape[1]-segment_size,image.shape[1]])\n",
    "    \n",
    "    return images, pos, segment_size\n",
    "    \n",
    "        \n",
    "\n",
    "def segment_eval(model, image):\n",
    "    s_images, pos, sz = segment(image) \n",
    "    h,w = image.shape[0], image.shape[1]\n",
    "    \n",
    "    boxes = torch.empty((0,4),dtype = torch.int)\n",
    "    confs = torch.empty((0))\n",
    "    class_ids = torch.empty((0), dtype=torch.int)\n",
    "    \n",
    "    for sample_i, sample_pos in zip(s_images, pos):\n",
    "        results = model.predict(sample_i)[0]\n",
    "    \n",
    "        sample_boxes = results.boxes.xyxy.clone()\n",
    "        sample_boxes[:,0] = sample_boxes[:,0]+sample_pos[2]\n",
    "        sample_boxes[:,1] = sample_boxes[:,1]+sample_pos[0]\n",
    "        sample_boxes[:,2] = sample_boxes[:,2]+sample_pos[2]\n",
    "        sample_boxes[:,3] = sample_boxes[:,3]+sample_pos[0]\n",
    "        boxes = torch.cat((boxes,sample_boxes),dim=0)\n",
    "        \n",
    "        sample_conf = results.boxes.conf\n",
    "        confs = torch.cat((confs,sample_conf),dim=0)\n",
    "        \n",
    "        sample_cids = results.boxes.cls\n",
    "        class_ids = torch.cat((class_ids, sample_cids),dim=0)\n",
    "    keep_indices = torch.ops.torchvision.nms(boxes, confs, 0.2)\n",
    "        \n",
    "    return boxes.to(torch.int)[keep_indices], confs[keep_indices], class_ids.to(torch.int)[keep_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be1e6aae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T20:21:16.451675Z",
     "iopub.status.busy": "2024-06-05T20:21:16.450781Z",
     "iopub.status.idle": "2024-06-05T20:21:16.458704Z",
     "shell.execute_reply": "2024-06-05T20:21:16.457789Z"
    },
    "papermill": {
     "duration": 5.161208,
     "end_time": "2024-06-05T20:21:16.460591",
     "exception": false,
     "start_time": "2024-06-05T20:21:11.299383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_image_with_boxes(image, boxes, confidences, class_ids, class_names):\n",
    "    \"\"\"\n",
    "    Plot image with bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "    - image: numpy array representing the image\n",
    "    - boxes: list of bounding boxes in xyxy format\n",
    "    - confidences: list of confidence scores\n",
    "    - class_ids: list of class IDs\n",
    "    - class_names: list of class names\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.imshow(image)\n",
    "\n",
    "    for box, confidence, class_id in zip(boxes, confidences, class_ids):\n",
    "        x1, y1, x2, y2 = box\n",
    "        box_width = x2 - x1\n",
    "        box_height = y2 - y1\n",
    "        \n",
    "        # Create a rectangle patch\n",
    "        rect = patches.Rectangle((x1, y1), box_width, box_height, linewidth=1, edgecolor='r', facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add class label and confidence score\n",
    "        class_name = class_names[class_id]\n",
    "        ax.text(x1, y1, f'{class_name} {confidence:.2f}', color='r', fontsize=8, backgroundcolor='none')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d754e806",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T20:21:26.755924Z",
     "iopub.status.busy": "2024-06-05T20:21:26.755184Z",
     "iopub.status.idle": "2024-06-05T20:21:26.759688Z",
     "shell.execute_reply": "2024-06-05T20:21:26.758732Z"
    },
    "papermill": {
     "duration": 5.194229,
     "end_time": "2024-06-05T20:21:26.761525",
     "exception": false,
     "start_time": "2024-06-05T20:21:21.567296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# img = imageio.imread('/kaggle/input/pestvision-val/real_dset/images/val/00dc2285-26d5-406d-9632-b867fbb84adc.jpg')\n",
    "# model = PestDetection_yolov8(device)\n",
    "# model.load_model('/kaggle/input/yolo/other/exp1/14/last.pt')\n",
    "# boxes, confs, class_ids = segment_eval(model.model, img)\n",
    "# plot_image_with_boxes(img,boxes,confs,class_ids,[str(i) for i in range(1,103)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7794580f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T20:21:36.883549Z",
     "iopub.status.busy": "2024-06-05T20:21:36.883111Z",
     "iopub.status.idle": "2024-06-05T20:21:36.888178Z",
     "shell.execute_reply": "2024-06-05T20:21:36.887160Z"
    },
    "papermill": {
     "duration": 5.064941,
     "end_time": "2024-06-05T20:21:36.890160",
     "exception": false,
     "start_time": "2024-06-05T20:21:31.825219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_path = '/kaggle/input/pest-new-real/Pest Data-3/train2017'\n",
    "# anno_path = '/kaggle/input/pest-new-real/Pest Data-3/annotations/instances_train2017.json'\n",
    "\n",
    "# with open(anno_path, 'r') as f:\n",
    "#     anno = json.load(f)\n",
    "    \n",
    "# print(anno['categories'][0].keys())\n",
    "# print(anno['annotations'][0].keys())\n",
    "# print(anno['images'][0].keys())\n",
    "# print([i['id'] for i in anno['images'] if i['file_name']=='061.jpg'])\n",
    "# print([j['bbox'] for j in anno['annotations'] if j['image_id']==1765])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5317f12a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T20:21:47.160818Z",
     "iopub.status.busy": "2024-06-05T20:21:47.159977Z",
     "iopub.status.idle": "2024-06-05T20:21:47.164928Z",
     "shell.execute_reply": "2024-06-05T20:21:47.164084Z"
    },
    "papermill": {
     "duration": 5.020305,
     "end_time": "2024-06-05T20:21:47.166743",
     "exception": false,
     "start_time": "2024-06-05T20:21:42.146438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image_p = './data1/images/train'\n",
    "# label_p = './data1/labels/train'\n",
    "\n",
    "# if not os.path.exists(image_p):\n",
    "#     os.makedirs(image_p)\n",
    "# if not os.path.exists(label_p):\n",
    "#     os.makedirs(label_p)\n",
    "\n",
    "# # print(len(os.listdir(train_path)))\n",
    "# cnt = 0\n",
    "# for i in anno['images']:\n",
    "#     if os.path.isfile(os.path.join(train_path,i['file_name'])):\n",
    "#         img = Image.open(os.path.join(train_path,i['file_name']))\n",
    "#         img.save(os.path.join(image_p,i['file_name']))\n",
    "\n",
    "#         with open(os.path.join(label_p,i['file_name'].split('.')[0]+'.txt'), 'w') as f:\n",
    "#             i_anno = [j for j in anno['annotations'] if j['image_id']==i['id']]\n",
    "#             for j in i_anno:\n",
    "#                 cate = 0\n",
    "#                 x = (j['bbox'][0]+j['bbox'][2]/2)/i['width']\n",
    "#                 y = (j['bbox'][1]+j['bbox'][3]/2)/i['height']\n",
    "#                 w = j['bbox'][2]/i['width']\n",
    "#                 h = j['bbox'][3]/i['height']\n",
    "#                 f.write(' '.join(map(str,[cate,x,y,w,h]))+'\\n')\n",
    "#         cnt+=1\n",
    "# print('Successful:',cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec7c414f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T20:21:57.263448Z",
     "iopub.status.busy": "2024-06-05T20:21:57.262607Z",
     "iopub.status.idle": "2024-06-05T20:21:57.283925Z",
     "shell.execute_reply": "2024-06-05T20:21:57.283031Z"
    },
    "papermill": {
     "duration": 5.052043,
     "end_time": "2024-06-05T20:21:57.285820",
     "exception": false,
     "start_time": "2024-06-05T20:21:52.233777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def resize_and_pad(img, target_size):\n",
    "    h, w = img.shape[:2]\n",
    "    scale = min(target_size / h, target_size / w)\n",
    "    nh, nw = int(h * scale), int(w * scale)\n",
    "    img_resized = cv2.resize(img, (nw, nh))\n",
    "    bot_pad = target_size - nh\n",
    "    right_pad = target_size - nw\n",
    "    img_padded = cv2.copyMakeBorder(img_resized, 0, bot_pad, 0, right_pad, cv2.BORDER_CONSTANT, value=(0, 0, 0))\n",
    "    return img_padded, scale, bot_pad, right_pad\n",
    "\n",
    "def adjust_labels(labels, scale, bot_pad, right_pad, cell_size):\n",
    "    adjusted_labels = []\n",
    "    \n",
    "    for label in labels:\n",
    "        cls, cx, cy, w, h = label\n",
    "        cx = (cx*(cell_size-right_pad))/cell_size\n",
    "        cy = (cy*(cell_size-bot_pad))/cell_size\n",
    "        w = (w*(cell_size-right_pad))/cell_size\n",
    "        h = (h*(cell_size-bot_pad))/cell_size\n",
    "        adjusted_labels.append([cls, cx, cy , w , h])\n",
    "    return adjusted_labels\n",
    "\n",
    "def fuse(n, img_paths, label_paths, dest_image, dest_label, n_img):\n",
    "    if not os.path.exists(dest_image):\n",
    "        os.makedirs(dest_image)\n",
    "    if not os.path.exists(dest_label):\n",
    "        os.makedirs(dest_label)\n",
    "    target_size = 512\n",
    "    cell_size = target_size // n\n",
    "    \n",
    "    img_files = sorted([os.path.join(p, f) for p in img_paths for f in os.listdir(p) if f.endswith(('.png', '.jpg', '.jpeg'))])\n",
    "    label_files = sorted([os.path.join(p, f) for p in label_paths for f in os.listdir(p) if f.endswith('.txt')])\n",
    "    \n",
    "    \n",
    "    assert len(img_files) == len(label_files), \"Number of image and label files should be the same\"\n",
    "    \n",
    "#     for i in range(len(img_files)):\n",
    "    for i in range(n_img):\n",
    "        img_fused = np.zeros((target_size, target_size, 3), dtype=np.uint8)\n",
    "        all_labels = []\n",
    "        \n",
    "        selected_indices = random.sample(range(len(img_files)), n*n)\n",
    "        idx = 0\n",
    "        \n",
    "        for row in range(n):\n",
    "            for col in range(n):\n",
    "                img_path = img_files[selected_indices[idx]]\n",
    "                label_path = label_files[selected_indices[idx]]\n",
    "                \n",
    "                img = cv2.imread(img_path)\n",
    "                labels = [] #\n",
    "                with open(label_path, 'r') as f:\n",
    "                    labels = [list(map(float, line.strip().split())) for line in f.readlines()]\n",
    "                \n",
    "                img_resized, scale, top_pad, right_pad = resize_and_pad(img, cell_size)\n",
    "                \n",
    "                start_y, start_x = row * cell_size, col * cell_size\n",
    "                img_fused[start_y:start_y + cell_size, start_x:start_x + cell_size] = img_resized[:cell_size, :cell_size]\n",
    "                \n",
    "                adjusted_labels = adjust_labels(labels, scale, top_pad, right_pad, cell_size)\n",
    "                for label in adjusted_labels:\n",
    "                    cls, cx, cy, w, h = label\n",
    "                    cx = (cx * cell_size + start_x) / target_size\n",
    "                    cy = (cy * cell_size + start_y) / target_size\n",
    "                    w /= n\n",
    "                    h /= n\n",
    "                    all_labels.append([cls, cx, cy, w, h])\n",
    "                \n",
    "                idx += 1\n",
    "        \n",
    "        img_filename = os.path.join(dest_image, f'fused_{i}.jpg')\n",
    "        cv2.imwrite(img_filename, img_fused)\n",
    "        \n",
    "        label_filename = os.path.join(dest_label, f'fused_{i}.txt')\n",
    "        with open(label_filename, 'w') as f:\n",
    "            for label in all_labels:\n",
    "                f.write(' '.join(map(str, label)) + '\\n')\n",
    "\n",
    "# Example usage:back\n",
    "# fuse(1, ['/kaggle/input/realpestdet/data1/images/train'], ['/kaggle/input/realpestdet/data1/labels/train'],'online_real/images/train', 'online_real/labels/train',2000)\n",
    "# fuse(1, ['/kaggle/input/pestvisiondata/pestvision/pestvision_data/background_data/paddy_disease_classification/train/normal','/kaggle/input/pestvisiondata/pestvision/pestvision_data/background_data/paddy_disease_classification/train/dead_heart','/kaggle/input/pestvisiondata/pestvision/pestvision_data/background_data/RiceLeafs/train/blast','/kaggle/input/pestvisiondata/pestvision/pestvision_data/background_data/RiceLeafs/train/normal'], [],'background/images/train', 'background/labels/train',800)\n",
    "# fuse(1, ['/kaggle/input/realpestdet/data/images/train'], ['/kaggle/input/realpestdet/data/labels/train'],'ip102/images/train', 'ip102/labels/train',4000)\n",
    "# fuse(2, ['/kaggle/input/realpestdet/background/images/train','/kaggle/input/online-ip102/ip102/images/train'], ['/kaggle/input/realpestdet/background/labels/train','/kaggle/input/online-ip102/ip102/labels/train'],'data/fuse2/images/train', 'data/fuse2/labels/train',10000)\n",
    "# fuse(4, ['/kaggle/input/realpestdet/background/images/train','/kaggle/input/online-ip102/ip102/images/train'], ['/kaggle/input/realpestdet/background/labels/train','/kaggle/input/online-ip102/ip102/labels/train'],'data/fuse4/images/train', 'data/fuse4/labels/train',10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5e64bb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T20:22:07.547386Z",
     "iopub.status.busy": "2024-06-05T20:22:07.546467Z",
     "iopub.status.idle": "2024-06-05T20:22:07.550683Z",
     "shell.execute_reply": "2024-06-05T20:22:07.549847Z"
    },
    "papermill": {
     "duration": 5.086179,
     "end_time": "2024-06-05T20:22:07.552647",
     "exception": false,
     "start_time": "2024-06-05T20:22:02.466468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# with open('data/labels/train/fused_72.txt','r') as f:\n",
    "#     data = f.readlines()\n",
    "# print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "522d9d78",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-05T20:22:17.888323Z",
     "iopub.status.busy": "2024-06-05T20:22:17.887952Z",
     "iopub.status.idle": "2024-06-05T20:22:17.897339Z",
     "shell.execute_reply": "2024-06-05T20:22:17.896462Z"
    },
    "papermill": {
     "duration": 5.178449,
     "end_time": "2024-06-05T20:22:17.899232",
     "exception": false,
     "start_time": "2024-06-05T20:22:12.720783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_using_box(img_path, label_path):\n",
    "    img = np.array(Image.open(img_path), dtype = np.uint8)\n",
    "    with open(label_path,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    labels = [[float(j) for j in i.split()] for i in lines]\n",
    "    adjusted_labels = []\n",
    "    H,W,C = img.shape\n",
    "    for i in labels:\n",
    "        x,y,w,h = i[1], i[2], i[3], i[4]\n",
    "        x1 = int((x-w/2)*W)\n",
    "        x2 = int((x+w/2)*W)        \n",
    "        y1 = int((y-h/2)*H)        \n",
    "        y2 = int((y+h/2)*H)\n",
    "        adjusted_labels.append([x1,y1,x2,y2])\n",
    "    plot_image_with_boxes(img, adjusted_labels, [1 for i in range(len(labels))], [0 for i in range(len(labels))], ['1' for i in range(len(labels))])\n",
    "    \n",
    "# plot_using_box('/kaggle/working/data/fuse4/images/train/fused_30.jpg','/kaggle/working/data/fuse4/labels/train/fused_30.txt')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5072195,
     "sourceId": 8519059,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5139886,
     "sourceId": 8592563,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5147212,
     "sourceId": 8602666,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5148546,
     "sourceId": 8604487,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5095802,
     "isSourceIdPinned": false,
     "sourceId": 8611930,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 46883,
     "sourceId": 61060,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelInstanceId": 46883,
     "sourceId": 61067,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 13753.61946,
   "end_time": "2024-06-05T20:22:25.939103",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-06-05T16:33:12.319643",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
